{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21815,
     "status": "ok",
     "timestamp": 1667234557531,
     "user": {
      "displayName": "Kapchenko Nikita",
      "userId": "13103833174454489193"
     },
     "user_tz": -60
    },
    "id": "SaOlNWG3sIxo",
    "outputId": "bbc85c13-4edc-4950-8b40-97b0ac0a49c8"
   },
   "outputs": [],
   "source": [
    "# Use below line for demo in external colabs\n",
    "#  !pip install -q git+https://github.com/nikitakapitan/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 381,
     "status": "ok",
     "timestamp": 1667235645442,
     "user": {
      "displayName": "Kapchenko Nikita",
      "userId": "13103833174454489193"
     },
     "user_tz": -60
    },
    "id": "WN8Jccx1sYXG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from transformers.main import make_model\n",
    "\n",
    "from transformers.Embeddings import Embeddings\n",
    "from transformers.PositionalEncoding import PositionalEncoding\n",
    "from transformers.MultiHeadedAttention import MultiHeadedAttention\n",
    "from transformers.helper import following_mask\n",
    "from transformers.LayerNorm import LayerNorm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1041,
     "status": "ok",
     "timestamp": 1667234558567,
     "user": {
      "displayName": "Kapchenko Nikita",
      "userId": "13103833174454489193"
     },
     "user_tz": -60
    },
    "id": "_hV9cbyH_59h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10]) torch.Size([1, 1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikitakapitan/GitHub/venvai/lib/python3.10/site-packages/torch/nn/modules/linear.py:96: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:77.)\n",
      "  self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n"
     ]
    }
   ],
   "source": [
    "D_MODEL = 32\n",
    "D_FF = 2048\n",
    "N = 2 #layers\n",
    "H = 8 #heads\n",
    "\n",
    "n = 10 #tokens in input\n",
    "\n",
    "mapa = {1 : 'b', 2 : 'layers', 8 : 'h', 4 : 'd_head', \n",
    "        10 : 'n', 32 : 'emb/d_model', 2048 : 'd_ff' }\n",
    "\n",
    "\n",
    "FRENCH = 11 #SOURCE : number of all words in French  vocab\n",
    "ENGLISH  = 11 #TARGET : number of all words in English vocab\n",
    "\n",
    "# INITIALIZE\n",
    "test_model = make_model(src_vocab=FRENCH, tgt_vocab=ENGLISH, N=N)\n",
    "test_model.eval() # switch to eval (no DropOut & BatchNorm learning)\n",
    "\n",
    "# INFERENCE\n",
    "src = torch.LongTensor([range(1,n+1)])\n",
    "src_mask = torch.ones(1,1,n)\n",
    "print(src.shape, src_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = test_model.encode(src, src_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CezVbVlt_bjl"
   },
   "source": [
    "# Down-brake **Model.encode(src, src_mask)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 381,
     "status": "ok",
     "timestamp": 1667237041900,
     "user": {
      "displayName": "Kapchenko Nikita",
      "userId": "13103833174454489193"
     },
     "user_tz": -60
    },
    "id": "oA9cbRs5_YyA",
    "outputId": "96f2ae2c-a05a-4588-916e-1f24b5487f83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = src\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1667237042924,
     "user": {
      "displayName": "Kapchenko Nikita",
      "userId": "13103833174454489193"
     },
     "user_tz": -60
    },
    "id": "zsy6CDaDnVZI",
    "outputId": "f8869c79-8c3c-4773-9095-abe6b5237a78"
   },
   "outputs": [],
   "source": [
    "emb = Embeddings(vocab=FRENCH, d_model=D_MODEL)\n",
    "x = emb(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rl8KmYjjAYpu"
   },
   "source": [
    "## Step 2 PositionEncoding(d_model, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "executionInfo": {
     "elapsed": 308,
     "status": "error",
     "timestamp": 1667237050666,
     "user": {
      "displayName": "Kapchenko Nikita",
      "userId": "13103833174454489193"
     },
     "user_tz": -60
    },
    "id": "Znjm0RX37t3h",
    "outputId": "cd699ef8-2d7f-41d9-b06d-2d6be65e777c"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 5000\n",
    "pos_enc = PositionalEncoding(d_model=D_MODEL, dropout=DROPOUT, max_len=MAX_LEN)\n",
    "x = pos_enc(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Start step 3 ResidualConnection (input 3)\n",
    "## Step 4 MultiHeadedAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1667238034167,
     "user": {
      "displayName": "Kapchenko Nikita",
      "userId": "13103833174454489193"
     },
     "user_tz": -60
    },
    "id": "xevj1lyzCiy8",
    "outputId": "82e18b16-fa55-4513-9e6d-bd388c1076a7"
   },
   "outputs": [],
   "source": [
    "attn = MultiHeadedAttention(h=H, d_model=D_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.1 Query, Key, Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "maylguAWDMwY"
   },
   "outputs": [],
   "source": [
    "# MultiHeadedAttention.__init__\n",
    "d_head = D_MODEL // H\n",
    "h = H\n",
    "q_fc = nn.Linear(D_MODEL, D_MODEL)\n",
    "k_fc = nn.Linear(D_MODEL, D_MODEL)\n",
    "v_fc = nn.Linear(D_MODEL, D_MODEL)\n",
    "final_fc = nn.Linear(D_MODEL, D_MODEL)\n",
    "dropout = nn.Dropout(p=DROPOUT)\n",
    "\n",
    "input_3 = x\n",
    "mask = src_mask\n",
    "\n",
    "# MultiHeadedAttention.forward : compute Query, Key, Value\n",
    "mask = mask.unsqueeze(1)\n",
    "print('mask shape=',mask.shape)\n",
    "n_batches = input_3.size(0) # 1\n",
    "\n",
    "print('input.shape=', [mapa[e] for e in input_3.shape])\n",
    "query = q_fc(input_3)\n",
    "key = k_fc(input_3)\n",
    "value = v_fc(input_3)\n",
    "\n",
    "print('query.shape=', [mapa[e] for e in query.shape])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.2 Split to H heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into H heads.\n",
    "query = query.view(n_batches, n, h, d_head) .transpose(1, 2)\n",
    "key = key.view(n_batches, n, h, d_head).transpose(1, 2)\n",
    "value = value.view(n_batches, n, h, d_head).transpose(1, 2)\n",
    "query.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.3 Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def attention\n",
    "key_t = key.transpose(-2, -1)\n",
    "print('query.shape=', [mapa[e] for e in query.shape])\n",
    "print('key_t.shape=', [mapa[e] for e in key_t.shape])\n",
    "\n",
    "scores = torch.matmul(query, key_t) / math.sqrt(d_head)\n",
    "print('scores.shape=', [mapa[e] for e in scores.shape])\n",
    "\n",
    "scores = scores.masked_fill(mask, -1e9)\n",
    "\n",
    "p_attn = scores.softmax(dim=-1)\n",
    "print('p_attn.shape=', [mapa[e] for e in p_attn.shape])\n",
    "\n",
    "# if dropout is not None:\n",
    "#     p_attn = dropout(p_attn)\n",
    "\n",
    "print('value.shape=', [mapa[e] for e in value.shape])\n",
    "headed_context = torch.matmul(p_attn, value)\n",
    "print('headed_context.shape=', [mapa[e] for e in headed_context.shape])\n",
    "\n",
    "context = headed_context.transpose(1,2).contiguous().view(n_batches, n, h * d_head)\n",
    "print('context.shape=', [mapa[e] for e in context.shape])\n",
    "\n",
    "output_4 = final_fc(context)\n",
    "print('output_4.shape=', [mapa[e] for e in output_4.shape])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = LayerNorm(D_MODEL)\n",
    "output_5 = norm(output_4)\n",
    "print('output_5.shape=', [mapa[e] for e in output_5.shape])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 Residual Connectnion (output 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end ResidualConnection\n",
    "output_3 = input_3 + output_5\n",
    "print('output_3.shape=', [mapa[e] for e in output_3.shape])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Start Step 6 Residual Connecction (input 6)\n",
    "\n",
    "## Step 7 PositionalWiseFeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_1 = nn.Linear(D_MODEL, D_FF)\n",
    "w_2 = nn.Linear(D_FF, D_MODEL)\n",
    "\n",
    "fc1 = w_1(output_3).relu() # + DropOut\n",
    "print('fc1.shape=', [mapa[e] for e in fc1.shape])\n",
    "output_7 = w_2(fc1)\n",
    "print('output_7.shape=', [mapa[e] for e in output_7.shape])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = LayerNorm(D_MODEL)\n",
    "output_8 = norm(output_7)\n",
    "print('output_8.shape=', [mapa[e] for e in output_8.shape])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 ResidualConnection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_6 = output_8 + output_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 : Repeat N times loop Step3-Step8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Untrained Model Prediction: tensor([[0, 2, 7, 2, 2, 2, 2, 2, 2, 2]])\n"
     ]
    }
   ],
   "source": [
    "tgt = torch.zeros(1, 1).type_as(src)\n",
    "\n",
    "for i in range(9):\n",
    "    tgt_mask = following_mask(tgt.size(1)).type_as(src.data)\n",
    "\n",
    "    out = test_model.decode(memory, src_mask, tgt, tgt_mask)\n",
    "\n",
    "    prob = test_model.generator(out[:, -1])\n",
    "\n",
    "    next_word = torch.argmax(prob, dim=1).unsqueeze(0)\n",
    "\n",
    "    tgt=torch.cat([tgt, next_word],dim=1)\n",
    "\n",
    "print(\"Example Untrained Model Prediction:\", tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Down-brake **Model.decode(memory, src_mask, tgt, tgt_mask)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Down-brake **Predict next word**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt = torch.zeros(1, 1).type_as(src)\n",
    "tgt_mask = following_mask(tgt.size(1)).type_as(src.data)\n",
    "\n",
    "prob = test_model.generator(out[:, -1])\n",
    "ext_word = torch.argmax(prob, dim=1).unsqueeze(0)\n",
    "\n",
    "tgt=torch.cat([tgt, next_word],dim=1)\n",
    "tgt\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMBa/2JyW7GewSx6ZS912U7",
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venvai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "0159b81555e194df7357f3ec66ac7a725116f7bdd06d05856166e90d27da3b92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
